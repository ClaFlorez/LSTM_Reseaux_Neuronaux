# ğŸ¬ Librairie IMDb â€” Jeu de DonnÃ©es pour lâ€™Analyse de Sentiments (Keras / TensorFlow)

## ğŸ§­ Introduction
Le **jeu de donnÃ©es IMDb** (*Internet Movie Database*) est un ensemble de critiques de films largement utilisÃ© pour entraÃ®ner et tester des modÃ¨les dâ€™**apprentissage automatique** et de **traitement du langage naturel (NLP)**.

Ce dataset est inclus dans la bibliothÃ¨que **Keras**, dÃ©veloppÃ©e par **FranÃ§ois Chollet** (Google), et distribuÃ©e avec **TensorFlow**.  
Il sert principalement Ã  **lâ€™analyse de sentiments** â€” câ€™est-Ã -dire dÃ©terminer si une critique de film est **positive** ou **nÃ©gative**.

---

## ğŸ§‘â€ğŸ’» Origine et CrÃ©ation
- **CrÃ©Ã© par :** lâ€™Ã©quipe Keras / TensorFlow (Google AI)  
- **BasÃ© sur :** les donnÃ©es publiques du site [IMDb.com](https://www.imdb.com)  
- **Auteur principal de Keras :** FranÃ§ois Chollet (Google Brain)  
- **But du dataset :** fournir un corpus textuel prÃªt Ã  lâ€™emploi pour lâ€™expÃ©rimentation et lâ€™enseignement des modÃ¨les sÃ©quentiels (RNN, LSTM, GRU, Transformersâ€¦)

---

## ğŸ“¦ Contenu du Dataset
| Ã‰lÃ©ment | Description |
|----------|-------------|
| **Nombre total dâ€™exemples** | 50 000 critiques de films |
| **Jeu dâ€™entraÃ®nement** | 25 000 critiques |
| **Jeu de test** | 25 000 critiques |
| **TÃ¢che** | Classification binaire (sentiment positif ou nÃ©gatif) |
| **Format** | DonnÃ©es textuelles converties en sÃ©quences numÃ©riques |
| **Langue** | Anglais |
| **Balance** | 50 % positives / 50 % nÃ©gatives |

---

## ğŸ§© Structure des DonnÃ©es
Chaque critique est dÃ©jÃ  **prÃ©traitÃ©e** et convertie en **sÃ©quence dâ€™entiers** reprÃ©sentant les mots du texte.  
Keras fournit aussi un **dictionnaire (`word_index`)** pour relier ces entiers aux mots dâ€™origine.

### Exemple :
```python
from tensorflow.keras.datasets import imdb
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)

print("Exemple de critique encodÃ©e :", X_train[0][:20])
print("Label associÃ© :", y_train[0])
```

ğŸ“¤ Sortie :
```
Exemple de critique encodÃ©e : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, ...]
Label associÃ© : 1
```
Chaque nombre correspond Ã  **un mot** selon un dictionnaire dâ€™index.

---

## ğŸ”¤ Le Dictionnaire des Mots
Le mapping entre mots et indices est accessible via :
```python
word_index = imdb.get_word_index()
print(list(word_index.items())[:10])
```

ğŸ“¥ Exemple :
```
[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ...]
```

On peut donc **reconstruire la phrase originale** :
```python
index_word = {v+3: k for k, v in word_index.items()}
index_word[0] = "<PAD>"
index_word[1] = "<START>"
index_word[2] = "<UNK>"
index_word[3] = "<UNUSED>"

def decode_review(encoded_review):
    return " ".join(index_word.get(i, "?") for i in encoded_review)

print(decode_review(X_train[0])[:200])
```

ğŸ” Les premiers tokens spÃ©ciaux :
| Code | Signification |
|-------|----------------|
| `0` | `<PAD>` â€” remplissage pour uniformiser la longueur |
| `1` | `<START>` â€” dÃ©but de la critique |
| `2` | `<UNK>` â€” mot inconnu |
| `3` | `<UNUSED>` â€” rÃ©servÃ© pour extensions futures |

---

## âš™ï¸ ParamÃ¨tres Importants de `load_data()`
```python
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000, skip_top=0, maxlen=None, seed=113)
```

| ParamÃ¨tre | Description |
|------------|--------------|
| `num_words` | Garde uniquement les *n* mots les plus frÃ©quents |
| `skip_top` | Ignore les mots les plus frÃ©quents (comme â€œtheâ€, â€œandâ€) |
| `maxlen` | Coupe les critiques trop longues |
| `seed` | Graine alÃ©atoire pour la reproductibilitÃ© |

---

## ğŸ“Š Statistiques
- Longueur moyenne dâ€™une critique : **233 mots**  
- Longueur maximale : **2 494 mots**  
- Taille du vocabulaire brut : **â‰ˆ 88 000 mots**  
- Taille typique aprÃ¨s `num_words=10000` : **10 000 mots**  
- RÃ©partition Ã©quilibrÃ©e : 25k positifs / 25k nÃ©gatifs

---

## ğŸ§  Utilisation Typique
Lâ€™objectif du dataset IMDb est de **tester des architectures sÃ©quentielles** :

| ModÃ¨le | Utilisation |
|--------|--------------|
| **RNN simple** | Baseline pour apprentissage sÃ©quentiel |
| **LSTM / GRU** | Gestion de la mÃ©moire Ã  long terme |
| **CNN 1D** | DÃ©tection locale de motifs linguistiques |
| **Transformers** | Contexte bidirectionnel (modÃ¨les modernes) |

---

## ğŸ§ª Exemple de Flux Complet
```python
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

# Chargement
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)
X_train = pad_sequences(X_train, maxlen=200)
X_test  = pad_sequences(X_test,  maxlen=200)

# ModÃ¨le
model = Sequential([
    Embedding(10000, 128),
    LSTM(128),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)
```

---

## ğŸ‘ï¸ Visualisation du Dataset (DÃ©codage)
Exemple de critique dÃ©codÃ©e :
```
<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played ...
```
Label :  
`1` â†’ **Critique positive**

---

## ğŸ” Avantages du Dataset IMDb
âœ… Facile Ã  charger (intÃ©grÃ© Ã  Keras)  
âœ… PrÃ©traitÃ© (pas besoin de nettoyage complexe)  
âœ… Ã‰quilibrÃ© et annotÃ©  
âœ… IdÃ©al pour la **dÃ©monstration de modÃ¨les NLP**  
âœ… Supporte des architectures variÃ©es (RNN, LSTM, GRU, CNN, Transformers)

---

## âš ï¸ Limites
âš ï¸ Langue unique : uniquement en anglais.  
âš ï¸ Jeu de donnÃ©es prÃ©traitÃ© (on ne voit pas le texte brut).  
âš ï¸ Impossible dâ€™ajouter facilement des critiques personnalisÃ©es dans la version intÃ©grÃ©e.  
âš ï¸ Pas adaptÃ© Ã  des analyses linguistiques profondes (les indices remplacent le vocabulaire original).

---

## ğŸ§­ Conclusion
Le dataset **IMDb** intÃ©grÃ© dans **Keras** est un outil pÃ©dagogique incontournable pour comprendre les rÃ©seaux neuronaux appliquÃ©s au texte.  
Il permet dâ€™apprendre les bases du **NLP (Natural Language Processing)** tout en testant des modÃ¨les sÃ©quentiels puissants comme le **LSTM**.

> ğŸ“ En rÃ©sumÃ© : simple, rapide, reproductible et parfait pour lâ€™enseignement.

---

## ğŸ“š RÃ©fÃ©rences
- FranÃ§ois Chollet, *Keras Documentation â€“ IMDb Dataset*  
- [TensorFlow â€“ IMDb Movie Review Dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)  
- [IMDb.com â€“ Internet Movie Database](https://www.imdb.com)

---

**Auteur :** Claud-IA  
ğŸ“ MontrÃ©al, 2025  
ğŸ§  *Projet de documentation IA â€“ Deep Learning et NLP*
